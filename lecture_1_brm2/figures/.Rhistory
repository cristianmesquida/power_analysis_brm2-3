alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id))
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": "paired samples t-test",
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": "cohen\'s D"
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309)
validate <- function(data1, observed_result, data2, expected_result) {
res1 <- data1 |>
select(id, observed_result)
res2 <- data2 |>
select(id, expected_result)
table <- inner_joint(res1, res2, by = id) |>
table$match <- mapply(identical, table[[observed_result]], table[[expected_result]])
return(table)
}
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_joint(data2 |>
select(id, expected_result), by = id) |>
rowwise() |>
mutate(match = identical(table[[observed_result]], table[[expected_result]]))
return(table)
}
df1 <- data.frame(apriori = rep("yes", "no"), 5)
df1 <- data.frame(apriori = rep(c("yes", "no"), 5))
df2 <- data.frame(apriori = rep(c("yes", "no"), 5))
df2
df2
df1 <- data.frame(e = rep(c("yes", "no"), 5))
df2 <- data.frame(o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_joint(data2 |>
select(id, expected_result), by = id) |>
rowwise() |>
mutate(match = identical(table[[observed_result]], table[[expected_result]])) |>
ungroup()
return(table)
}
validate(df1, e, o, apriori)
df1 <- data.frame(e = rep(c("yes", "no"), 5))
df2 <- data.frame(o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_join(data2 |>
select(id, expected_result), by = id) |>
rowwise() |>
mutate(match = identical(table[[observed_result]], table[[expected_result]])) |>
ungroup()
return(table)
}
validate(df1, e, o, apriori)
df1
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_join(data2 |>
select(id, expected_result), by = id) |>
rowwise() |>
mutate(match = identical(table[[observed_result]], table[[expected_result]])) |>
ungroup()
return(table)
}
validate(df1, e, o, apriori)
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_join(data2 |>
select(id, expected_result), by = id) |>
rowwise() |>
mutate(match = identical(table[[observed_result]], table[[expected_result]])) |>
ungroup()
return(table)
}
validate(df1, e, o, apriori)
validate(data1 = df1, o, data2 = df2, e)
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_join(data2 |>
select(id, expected_result), by = "id") |>
rowwise() |>
mutate(match = identical(cur_data()[[observed_result]], cur_data()[[expected_result]])) |>
ungroup()
return(table)
}
validate(data1 = df1, observed_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, observed_result) |>
inner_join(data2 |>
select(id, expected_result), by = "id") |>
rowwise() |>
mutate(match = identical(cur_data()[[observed_result]], cur_data()[[expected_result]])) |>
ungroup()
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, all_of(observed_result)) |>
inner_join(data2 |>
select(id, all_of(expected_result)), by = "id") |>
rowwise() |>
mutate(match = identical(cur_data()[[observed_result]], cur_data()[[expected_result]])) |>
ungroup()
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, all_of(observed_result)) |>
inner_join(data2 |>
select(id, all_of(expected_result)), by = "id") |>
rowwise() |>
mutate(match = identical(cur_data()[[observed_result]], cur_data()[[expected_result]])) |>
ungroup()
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- data1 |>
select(id, all_of(observed_result)) |>
inner_join(data2 |>
select(id, all_of(expected_result)), by = "id") |>
rowwise() |>
mutate(match = identical(cur_data()[[observed_result]], cur_data()[[expected_result]])) |>
ungroup()
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- inner_join(
data1 |> select(id, pick(observed_result)),
data2 |> select(id, pick(expected_result)),
by = "id")
table |> table(.datamutate[[observed_result]] == .data[[expected_result]])
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- inner_join(
data1 |> select(id, all_of(observed_result)),
data2 |> select(id, all_of(expected_result)),
by = "id")
table |> table(.datamutate[[observed_result]] == .data[[expected_result]])
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
df1 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
validate <- function(data1, observed_result, data2, expected_result) {
table <- inner_join(
data1 |> select(id, all_of(observed_result)),
data2 |> select(id, all_of(expected_result)),
by = "id")
table <- table |>
mutate(match = .data[[observed_result]] == .data[[expected_result]])
return(table)
}
validate(data1 = df1, expected_result = "e", data2 = df2, observed_result = "o")
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": "paired samples t-test",
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": "cohen\'s D"
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309)
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": "paired samples t-test",
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": "cohen\'s D"
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309)
df$type_standardised_es
df$intended_power
df$statistical_test_power
df <- read_xlsx("~/Desktop/power_validation/power_analysis.xlsx")
df |>
select(id = doi,
apriori = power_analysis,
sample = power_sample,
es = magnitude_es,
es_metric = type_standardised_es,
power = intended_power,
alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id)) |>
mutate(es_metric = case_when(
type_standardised_es == "Cohen's d family" ~ "Cohen's d",
type_standardised_es == "Hedge's g family" ~ "Hedge's g",
type_standardised_es == "eta partial squared (ηp^2)" ~ "partial eta squared",
TRUE ~ type_standardised_es
))
df <- read_xlsx("~/Desktop/power_validation/power_analysis.xlsx")
df |>
select(id = doi,
apriori = power_analysis,
sample = power_sample,
es = magnitude_es,
es_metric = type_standardised_es,
power = intended_power,
alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id)) |>
mutate(es_metric = case_when(
es_metric == "Cohen's d family" ~ "Cohen's d",
es_metric == "Hedge's g family" ~ "Hedge's g",
es_metric == "eta partial squared (ηp^2)" ~ "partial eta squared",
TRUE ~ type_standardised_es
))
df <- read_xlsx("~/Desktop/power_validation/power_analysis.xlsx")
df |>
select(id = doi,
apriori = power_analysis,
sample = power_sample,
es = magnitude_es,
es_metric = type_standardised_es,
power = intended_power,
alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id)) |>
mutate(es_metric = case_when(
es_metric == "Cohen's d family" ~ "Cohen's d",
es_metric == "Hedge's g family" ~ "Hedge's g",
es_metric == "eta partial squared (ηp^2)" ~ "partial eta squared",
TRUE ~  es_metric
))
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. If the test is an F-test, also extract the number of factors (e.g., one-way ANOVA). For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": ["paired t-test", "unpaired t-test", "one-way ANOVA, "two-way ANOVA],
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": ["Cohen\'s d", "Cohen\'s f", "Hedge\'s g", "partial eta squared"]
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309)
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. If the test is an F-test, also extract the number of factors (e.g., one-way ANOVA). For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": ["paired t-test", "unpaired t-test", "one-way ANOVA, "two-way ANOVA],
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": ["Cohen\'s d", "Cohen\'s f", "Hedge\'s g", "partial eta squared"]
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309,
API_KEY = Sys.getenv("GROQ_API_KEY"))
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. If the test is an F-test, also extract the number of factors (e.g., one-way ANOVA). For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": ["paired t-test", "unpaired t-test", "one-way ANOVA, "two-way ANOVA],
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": ["Cohen\'s d", "Cohen\'s f", "Hedge\'s g", "partial eta squared"]
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 175309)
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. If the test is an F-test, also extract the number of factors (e.g., one-way ANOVA). For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": ["paired t-test", "unpaired t-test", "one-way ANOVA, "two-way ANOVA],
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": ["Cohen\'s d", "Cohen\'s f", "Hedge\'s g", "partial eta squared"]
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_power <- llm(sample, query, seed = 8675309)
validate <- function(expected_result, e, observed_result, o) {
table <- inner_join(
expected_result |> select(id, all_of(e)),
observed_result |> select(id, all_of(o)),
by = "id")
table <- table |>
mutate(match = .data[[e]] == .data[[o]])
return(table)
}
df1 <- data.frame(id = 1:10, e = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, o = rep(c("yes", "no"), 5))
validate(df1, var1 = "e", data2 = df2, var2 = "o")
df1 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
validate(df1, var , df2, var)
validate <- function(expected_result, e, observed_result, o) {
table <- inner_join(
expected_result |> select(id, all_of(e)),
observed_result |> select(id, all_of(o)),
by = "id")
table <- table |>
mutate(match = .data[[e]] == .data[[o]])
return(table)
}
df1 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
validate(df1, var , df2, var)
df1 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
validate(df1, var, df2, var)
df1 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
validate(df1, "var", df2, "var")
df1 <- data.frame(id = 1:10, var1 = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var2 = rep(c("yes", "no"), 5))
validate(df1, "var1", df2, "var2")
df1 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var = rep(c("yes", "no"), 5))
validate(df1, "var", df2, "var")
df1 <- data.frame(id = 1:10, var1 = rep(c("yes", "no"), 5))
df2 <- data.frame(id = 1:10, var2 = rep(c("yes", "no"), 5))
validate(df1, "var1", df2, "var2")
power_sample_validation[1:346]
df
df
inner_join(power_sample_validation, df, by = "id")
power_sample_validation[1]
power_sample_validation[, 1]
names(power_sample_validation)
df <- read_xlsx("~/Desktop/power_validation/power_analysis.xlsx")
df |>
select(id = doi,
apriori = power_analysis,
sample = power_sample,
es = magnitude_es,
es_metric = type_standardised_es,
power = intended_power,
alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id)) |>
mutate(es_metric = case_when(
es_metric == "Cohen's d family" ~ "Cohen's d",
es_metric == "Hedge's g family" ~ "Hedge's g",
es_metric == "eta partial squared (ηp^2)" ~ "partial eta squared",
TRUE ~  es_metric
))
df
sample <- power_sample_validation[1:20]
word_pattern <- "(a[- ]?(priori )?power|(statistical )?power|G\\*Power)"
numeric_pattern <- "[0-9]|one|two|three|four|five|six|seven|eight|nine|ten"
sample_llm <- search_text(
sample,
pattern = word_pattern,
section = "method",
return = "paragraph"
) |>
search_text(
numeric_pattern,
return = "paragraph"
) |>
distinct(id)
word_pattern <- "(a[- ]?(priori )?power|(statistical )?power|G\\*Power)"
numeric_pattern <- "[0-9]|one|two|three|four|five|six|seven|eight|nine|ten"
sample_llm <- search_text(
sample,
pattern = word_pattern,
section = "method",
return = "paragraph"
) |>
search_text(
numeric_pattern,
return = "paragraph"
) |>
distinct(id)
sample_llm
usethis::edit_r_environ()
# ask a specific question with specific response format
query <- 'An a priori power analysis is used to estimate the required sample size to achieve a desired level of statistical power given an effect size, statistical test and alpha level.Determine whether the paragraph reports an a priori power analysis. If it does, extract the following information: the statistical test, sample size, critical alpha criterion, power level, effect size magnitude and the effect size metric. If the test is an F-test, also extract the number of factors (e.g., one-way ANOVA). For the effect size metric, only standardized effect sizes are valid, such as Cohen\'s d, Cohen\'s f or partial eta squared. Return the extracted information in JSON format witht the fields:
{
"apriori": true,
"test": ["paired t-test", "unpaired t-test", "one-way ANOVA, "two-way ANOVA"],
"sample": 20,
"alpha": 0.05,
"power": 0.8,
"es": 0.4,
"es_metric": ["Cohen\'s d", "Cohen\'s f", "Hedge\'s g", "partial eta squared"]
}
If not, return {"apriori": false}
Answer only in valid JSON format, starting with { and ending with }.'
llm_results <- llm(sample_llm, query, seed = 8675309)
df <- read_xlsx("~/Desktop/power_validation/power_analysis.xlsx")
df <- df |>
select(id = doi,
apriori = power_analysis,
sample = power_sample,
es = magnitude_es,
es_metric = type_standardised_es,
power = intended_power,
alpha = alpha_level,
test = statistical_test_power) |>
mutate(id = gsub("/", ":", id)) |>
mutate(es_metric = case_when(
es_metric == "Cohen's d family" ~ "Cohen's d",
es_metric == "Hedge's g family" ~ "Hedge's g",
es_metric == "eta partial squared (ηp^2)" ~ "partial eta squared",
TRUE ~  es_metric
))
data.frame(as.tibbel(names(power_sample_validation)), df$id)
data.frame(as.tibble(names(power_sample_validation)), df$id)
data.frame(as_tibble(names(power_sample_validation)), df$id)
as_tibble(names(power_sample_validation)), df$id)
inner_join(i, df$id, by = "id")
i <- data.frame(names = names(power_sample_validation))
inner_join(i, df$id, by = "id")
i
df$id
df
inner_join(i, df, by = "id")
i
i <- data.frame(id = names(power_sample_validation))
inner_join(i, df, by = "id")
setwd("~/Desktop/ethical_research/")
setwd("~/Desktop/ethical_research")
setwd("~/Desktop/ethical_research/")
knitr::opts_chunk$set(echo = FALSE)
knitr::include_graphics("~/Desktop/ethical_research/figures/fig1.png")
knitr::include_graphics("~/Desktop/ethical_research/figures/fig9.pdf")
knitr::include_graphics("~/Desktop/ethical_research/figures/table2.png")
knitr::opts_chunk$set(echo = FALSE)
knitr::include_graphics("~/Desktop/ethical_research/figures/fig1.png")
knitr::include_graphics("~/Desktop/ethical_research/figures/fig7.pdf")
knitr::include_graphics("~/Desktop/ethical_research/figures/fig7.pdf")
install.packages("rcrossref")
install.packages("rcrossref")
pdf <- "~/Desktop/workshop_papercheck/manuscript.pdf"
xml <- "~/Desktop/workshop_papercheck/manuscript.xml"
pdf2grobid(pdf,
save_path = xml,
grobid_url = "https://thesanogoeffect-grobid-papercheck.hf.space")
library(rcrossref)  # use crossref to get info
library(papercheck) # load papercheck
library(dplyr)      # for data wrangling
pdf <- "~/Desktop/workshop_papercheck/manuscript.pdf"
xml <- "~/Desktop/workshop_papercheck/manuscript.xml"
pdf2grobid(pdf,
save_path = xml,
grobid_url = "https://thesanogoeffect-grobid-papercheck.hf.space")
setwd("~/Desktop/brm/sample_size/figures/")
setwd("~/Desktop/brm/sample_size/figures/")
setwd("~/Dropbox/brm/sample_size/figures/")
